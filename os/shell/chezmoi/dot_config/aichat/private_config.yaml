# see https://github.com/sigoden/aichat/blob/main/config.example.yaml

model: openai:gpt-4o
stream: true
save: true

clients:
  - type: openai-compatible
    name: mlx
    api_base: http://localhost:8080/v1
    api_key:
    models:
      - name: mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit
        max_input_tokens: 32768

  - type: openai-compatible
    name: ollama
    api_base: http://localhost:11434/v1
    models:
      - name: qwen:latest
        max_input_tokens: 32768
      - name: qwen2.5-coder:14b
        max_input_tokens: 32768
      - name: qwen3:8b
        max_input_tokens: 32768

  - type: openai
    models:
      - name: gpt-4o
        max_input_tokens: 128000
      - name: gpt-4o-mini
        max_input_tokens: 128000
